{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "! pip install sacrebleu sentencepiece &> /dev/null\n",
    "! pip install nltk==3.2.4"
   ],
   "metadata": {
    "id": "B-XBkrkOcDo5",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:05:30.903427Z",
     "iopub.execute_input": "2022-07-19T10:05:30.903852Z",
     "iopub.status.idle": "2022-07-19T10:05:52.989647Z",
     "shell.execute_reply.started": "2022-07-19T10:05:30.903763Z",
     "shell.execute_reply": "2022-07-19T10:05:52.988339Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!rm ita-eng.zip &> /dev/null\n",
    "!rm rm -rf dataset &> /dev/null\n",
    "!wget \"https://www.manythings.org/anki/ita-eng.zip\" &> /dev/null\n",
    "!unzip \"ita-eng.zip\" -d \"dataset\" &> /dev/null\n",
    "\n",
    "text_file = \"dataset/ita.txt\""
   ],
   "metadata": {
    "id": "y6EgYLp5T-Tp",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:05:52.992167Z",
     "iopub.execute_input": "2022-07-19T10:05:52.992503Z",
     "iopub.status.idle": "2022-07-19T10:05:56.723071Z",
     "shell.execute_reply.started": "2022-07-19T10:05:52.992473Z",
     "shell.execute_reply": "2022-07-19T10:05:56.721819Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "from string import digits\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk\n",
    "import warnings; warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "id": "tnxXKDjq3jEL",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:05:56.726541Z",
     "iopub.execute_input": "2022-07-19T10:05:56.726863Z",
     "iopub.status.idle": "2022-07-19T10:06:01.900612Z",
     "shell.execute_reply.started": "2022-07-19T10:05:56.726834Z",
     "shell.execute_reply": "2022-07-19T10:06:01.899621Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_path = \"dataset/ita.txt\"\n",
    "sample_size = 250000\n",
    "EPOCHS = 5\n",
    "num_of_test = 30\n",
    "BATCH_SIZE = 128\n",
    "embedding_dim = 512\n",
    "units = 1024"
   ],
   "metadata": {
    "id": "e9S6YihQT8DI",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:01.903396Z",
     "iopub.execute_input": "2022-07-19T10:06:01.904036Z",
     "iopub.status.idle": "2022-07-19T10:06:01.908628Z",
     "shell.execute_reply.started": "2022-07-19T10:06:01.903997Z",
     "shell.execute_reply": "2022-07-19T10:06:01.907686Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Read the data\n",
    "lines_raw = pd.read_table(data_path,names=['source', 'target','copyright'])\n",
    "lines_raw.sample(5)"
   ],
   "metadata": {
    "id": "dKjxd5-3T8DK",
    "outputId": "72ac387e-5647-441e-c219-3305861d56d9",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:01.910085Z",
     "iopub.execute_input": "2022-07-19T10:06:01.910733Z",
     "iopub.status.idle": "2022-07-19T10:06:02.830440Z",
     "shell.execute_reply.started": "2022-07-19T10:06:01.910698Z",
     "shell.execute_reply": "2022-07-19T10:06:02.829366Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    #sentence = unicode_to_ascii(sentence.lower().strip())\n",
    "    num_digits= str.maketrans('','', digits)\n",
    "    \n",
    "    sentence= sentence.lower()\n",
    "    sentence= re.sub(\" +\", \" \", sentence)\n",
    "    sentence= re.sub(\"'\", '', sentence)\n",
    "    sentence= sentence.translate(num_digits)\n",
    "    sentence= sentence.strip()\n",
    "    sentence= re.sub(r\"([?.!,Â¿])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.rstrip().strip()\n",
    "    sentence=  'start_ ' + sentence + ' _end'\n",
    "    \n",
    "    return sentence"
   ],
   "metadata": {
    "id": "9xstxKx2T8DM",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:02.832049Z",
     "iopub.execute_input": "2022-07-19T10:06:02.834647Z",
     "iopub.status.idle": "2022-07-19T10:06:02.841169Z",
     "shell.execute_reply.started": "2022-07-19T10:06:02.834605Z",
     "shell.execute_reply": "2022-07-19T10:06:02.840119Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_dataset(path, num_examples):\n",
    "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "  return zip(*word_pairs)"
   ],
   "metadata": {
    "id": "OHn4Dct23jEm",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:02.842830Z",
     "iopub.execute_input": "2022-07-19T10:06:02.843194Z",
     "iopub.status.idle": "2022-07-19T10:06:02.851873Z",
     "shell.execute_reply.started": "2022-07-19T10:06:02.843159Z",
     "shell.execute_reply": "2022-07-19T10:06:02.851010Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "source, target, _ = create_dataset(data_path, sample_size)"
   ],
   "metadata": {
    "id": "cTbSbBz55QtF",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:02.855109Z",
     "iopub.execute_input": "2022-07-19T10:06:02.855389Z",
     "iopub.status.idle": "2022-07-19T10:06:15.026905Z",
     "shell.execute_reply.started": "2022-07-19T10:06:02.855349Z",
     "shell.execute_reply": "2022-07-19T10:06:15.025838Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def max_length(tensor):\n",
    "  return max(len(t) for t in tensor)"
   ],
   "metadata": {
    "id": "OmMZQpdO60dt",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:15.028645Z",
     "iopub.execute_input": "2022-07-19T10:06:15.028999Z",
     "iopub.status.idle": "2022-07-19T10:06:15.033771Z",
     "shell.execute_reply.started": "2022-07-19T10:06:15.028960Z",
     "shell.execute_reply": "2022-07-19T10:06:15.032783Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "source_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "source_sentence_tokenizer.fit_on_texts(source)\n",
    "source_tensor = source_sentence_tokenizer.texts_to_sequences(source)\n",
    "source_tensor= tf.keras.preprocessing.sequence.pad_sequences(source_tensor,padding='post' )"
   ],
   "metadata": {
    "id": "XmlIMMV2T8DQ",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:15.039325Z",
     "iopub.execute_input": "2022-07-19T10:06:15.040044Z",
     "iopub.status.idle": "2022-07-19T10:06:21.094705Z",
     "shell.execute_reply.started": "2022-07-19T10:06:15.040006Z",
     "shell.execute_reply": "2022-07-19T10:06:21.093620Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "target_sentence_tokenizer= tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "target_sentence_tokenizer.fit_on_texts(target)\n",
    "target_tensor = target_sentence_tokenizer.texts_to_sequences(target)\n",
    "target_tensor= tf.keras.preprocessing.sequence.pad_sequences(target_tensor,padding='post' )"
   ],
   "metadata": {
    "id": "mzKSm3H0T8DQ",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:21.096426Z",
     "iopub.execute_input": "2022-07-19T10:06:21.096800Z",
     "iopub.status.idle": "2022-07-19T10:06:26.396407Z",
     "shell.execute_reply.started": "2022-07-19T10:06:21.096764Z",
     "shell.execute_reply": "2022-07-19T10:06:26.395379Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Limit the size of the dataset to experiment faster (optional)\n",
    "\n",
    " To train faster, we can limit the size of the dataset using **sample_size** sentences (of course, translation quality degrades with less data):"
   ],
   "metadata": {
    "id": "GOi42V79Ydlr",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "max_target_length= max(len(t) for t in  target_tensor)\n",
    "print(max_target_length)\n",
    "max_source_length= max(len(t) for t in  source_tensor)\n",
    "print(max_source_length)"
   ],
   "metadata": {
    "id": "w1USJ8ZDT8DR",
    "outputId": "2695aaac-e083-4df0-be73-1621f395ff55",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:26.397802Z",
     "iopub.execute_input": "2022-07-19T10:06:26.398788Z",
     "iopub.status.idle": "2022-07-19T10:06:26.519854Z",
     "shell.execute_reply.started": "2022-07-19T10:06:26.398747Z",
     "shell.execute_reply": "2022-07-19T10:06:26.518847Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Creating Train and Test dataset"
   ],
   "metadata": {
    "id": "8IUlmsZZT8DR",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "source_train_tensor, source_test_tensor, target_train_tensor, target_test_tensor= train_test_split(source_tensor, target_tensor,test_size=0.2)"
   ],
   "metadata": {
    "id": "qDpLQR88T8DR",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:26.522173Z",
     "iopub.execute_input": "2022-07-19T10:06:26.523115Z",
     "iopub.status.idle": "2022-07-19T10:06:26.579344Z",
     "shell.execute_reply.started": "2022-07-19T10:06:26.523076Z",
     "shell.execute_reply": "2022-07-19T10:06:26.578329Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "#input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(source_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(source_train_tensor), len(source_test_tensor), len(target_train_tensor), len(target_test_tensor))"
   ],
   "metadata": {
    "id": "4QILQkOs3jFG",
    "outputId": "6c3077e7-f8c9-4c0a-b5ab-ec3a62e1a101",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:26.580708Z",
     "iopub.execute_input": "2022-07-19T10:06:26.581626Z",
     "iopub.status.idle": "2022-07-19T10:06:26.588478Z",
     "shell.execute_reply.started": "2022-07-19T10:06:26.581584Z",
     "shell.execute_reply": "2022-07-19T10:06:26.587386Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "BUFFER_SIZE = len(source_train_tensor)\n",
    "steps_per_epoch = len(source_train_tensor)//BATCH_SIZE\n",
    "vocab_inp_size = len(source_sentence_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(target_sentence_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((source_train_tensor, target_train_tensor)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ],
   "metadata": {
    "id": "TqHsArVZ3jFS",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:26.589982Z",
     "iopub.execute_input": "2022-07-19T10:06:26.590837Z",
     "iopub.status.idle": "2022-07-19T10:06:29.291063Z",
     "shell.execute_reply.started": "2022-07-19T10:06:26.590800Z",
     "shell.execute_reply": "2022-07-19T10:06:29.290083Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz, self.enc_units))"
   ],
   "metadata": {
    "id": "nZ2rI24i3jFg",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:29.294676Z",
     "iopub.execute_input": "2022-07-19T10:06:29.294995Z",
     "iopub.status.idle": "2022-07-19T10:06:29.305350Z",
     "shell.execute_reply.started": "2022-07-19T10:06:29.294966Z",
     "shell.execute_reply": "2022-07-19T10:06:29.304422Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:29.307146Z",
     "iopub.execute_input": "2022-07-19T10:06:29.308648Z",
     "iopub.status.idle": "2022-07-19T10:06:29.701446Z",
     "shell.execute_reply.started": "2022-07-19T10:06:29.308590Z",
     "shell.execute_reply": "2022-07-19T10:06:29.700360Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ],
   "metadata": {
    "id": "60gSVh05Jl6l",
    "outputId": "efc38bd3-9be0-4257-a212-04413676fa40",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:29.702763Z",
     "iopub.execute_input": "2022-07-19T10:06:29.703567Z",
     "iopub.status.idle": "2022-07-19T10:06:30.747145Z",
     "shell.execute_reply.started": "2022-07-19T10:06:29.703505Z",
     "shell.execute_reply": "2022-07-19T10:06:30.745977Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # hidden shape == (batch_size, hidden size)\n",
    "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # we are doing this to perform addition to calculate the score\n",
    "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ],
   "metadata": {
    "id": "umohpBN2OM94",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:30.748808Z",
     "iopub.execute_input": "2022-07-19T10:06:30.749425Z",
     "iopub.status.idle": "2022-07-19T10:06:30.761219Z",
     "shell.execute_reply.started": "2022-07-19T10:06:30.749369Z",
     "shell.execute_reply": "2022-07-19T10:06:30.760076Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ],
   "metadata": {
    "id": "k534zTHiDjQU",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:30.762946Z",
     "iopub.execute_input": "2022-07-19T10:06:30.763569Z",
     "iopub.status.idle": "2022-07-19T10:06:31.731241Z",
     "shell.execute_reply.started": "2022-07-19T10:06:30.763533Z",
     "shell.execute_reply": "2022-07-19T10:06:31.729224Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ],
   "metadata": {
    "id": "yJ_B3mhW3jFk",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:31.733514Z",
     "iopub.execute_input": "2022-07-19T10:06:31.734208Z",
     "iopub.status.idle": "2022-07-19T10:06:31.744438Z",
     "shell.execute_reply.started": "2022-07-19T10:06:31.734165Z",
     "shell.execute_reply": "2022-07-19T10:06:31.743424Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ],
   "metadata": {
    "id": "P5UY8wko3jFp",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:31.747634Z",
     "iopub.execute_input": "2022-07-19T10:06:31.748056Z",
     "iopub.status.idle": "2022-07-19T10:06:31.802362Z",
     "shell.execute_reply.started": "2022-07-19T10:06:31.748026Z",
     "shell.execute_reply": "2022-07-19T10:06:31.801275Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ],
   "metadata": {
    "id": "WmTHr5iV3jFr",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:31.803876Z",
     "iopub.execute_input": "2022-07-19T10:06:31.804199Z",
     "iopub.status.idle": "2022-07-19T10:06:31.812585Z",
     "shell.execute_reply.started": "2022-07-19T10:06:31.804165Z",
     "shell.execute_reply": "2022-07-19T10:06:31.811424Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "checkpoint_dir = 'training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ],
   "metadata": {
    "id": "Zj8bXQTgNwrF",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:31.814332Z",
     "iopub.execute_input": "2022-07-19T10:06:31.814847Z",
     "iopub.status.idle": "2022-07-19T10:06:31.823922Z",
     "shell.execute_reply.started": "2022-07-19T10:06:31.814811Z",
     "shell.execute_reply": "2022-07-19T10:06:31.823026Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
    "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
    "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
    "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "5. Use *teacher forcing* to decide the next input to the decoder.\n",
    "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
    "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
   ],
   "metadata": {
    "id": "hpObfY22IddU",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ],
   "metadata": {
    "id": "sC9ArXSsVfqn",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:31.825194Z",
     "iopub.execute_input": "2022-07-19T10:06:31.825622Z",
     "iopub.status.idle": "2022-07-19T10:06:31.836436Z",
     "shell.execute_reply.started": "2022-07-19T10:06:31.825585Z",
     "shell.execute_reply": "2022-07-19T10:06:31.835164Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} loss {}'.format(epoch + 1,batch, batch_loss.numpy()))\n",
    "   \n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ],
   "metadata": {
    "id": "ddefjBMa3jF0",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:06:31.837806Z",
     "iopub.execute_input": "2022-07-19T10:06:31.838347Z",
     "iopub.status.idle": "2022-07-19T10:30:49.720504Z",
     "shell.execute_reply.started": "2022-07-19T10:06:31.838311Z",
     "shell.execute_reply": "2022-07-19T10:30:49.719357Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Translate\n",
    "\n",
    "* The evaluate function is similar to the training loop, except we don't use *teacher forcing* here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.\n",
    "* Stop predicting when the model predicts the *end token* or when the max traget legth is reached\n",
    "* And store the *attention weights for every time step*.\n",
    "\n",
    "Note: The encoder output is calculated only once for one input."
   ],
   "metadata": {
    "id": "mU3Ce8M6I3rz",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate(sentence):\n",
    "  attention_plot = np.zeros((max_target_length, max_source_length))\n",
    "\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "  #print(sentence)\n",
    "  #print(source_sentence_tokenizer.word_index)\n",
    "\n",
    "  inputs = []\n",
    "  for i in sentence.split(' '):\n",
    "      try:\n",
    "        inputs.append(source_sentence_tokenizer.word_index[i])\n",
    "      except:\n",
    "        pass\n",
    "  #inputs = [source_sentence_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_source_length,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = [tf.zeros((1, units))]\n",
    "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  dec_input = tf.expand_dims([target_sentence_tokenizer.word_index['start_']], 0)\n",
    "\n",
    "  for t in range(max_target_length):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result += target_sentence_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "    if target_sentence_tokenizer.index_word[predicted_id] == '_end':\n",
    "      return result, sentence, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, sentence, attention_plot"
   ],
   "metadata": {
    "id": "EbQpyYs13jF_",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:30:49.722249Z",
     "iopub.execute_input": "2022-07-19T10:30:49.722619Z",
     "iopub.status.idle": "2022-07-19T10:30:49.735778Z",
     "shell.execute_reply.started": "2022-07-19T10:30:49.722580Z",
     "shell.execute_reply": "2022-07-19T10:30:49.734930Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## To Plot Attention weights"
   ],
   "metadata": {
    "id": "E028E3NaT8Dc",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "  fig = plt.figure(figsize=(10,10))\n",
    "  ax = fig.add_subplot(1, 1, 1)\n",
    "  ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "  fontdict = {'fontsize': 14}\n",
    "\n",
    "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "  plt.show()"
   ],
   "metadata": {
    "id": "s5hQWlbN3jGF",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:30:49.741809Z",
     "iopub.execute_input": "2022-07-19T10:30:49.742117Z",
     "iopub.status.idle": "2022-07-19T10:30:49.751235Z",
     "shell.execute_reply.started": "2022-07-19T10:30:49.742093Z",
     "shell.execute_reply": "2022-07-19T10:30:49.750247Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def translate(sentence, show_attention=False):\n",
    "  result, sentence, attention_plot = evaluate(sentence)\n",
    "  \n",
    "  if show_attention:\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))\n",
    "    \n",
    "  result = result.replace(\"_end\",\"\")\n",
    "  result = result.replace(\"start_\",\"\")\n",
    "  return result"
   ],
   "metadata": {
    "id": "sl9zUHzg3jGI",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:30:49.753281Z",
     "iopub.execute_input": "2022-07-19T10:30:49.753843Z",
     "iopub.status.idle": "2022-07-19T10:30:49.767529Z",
     "shell.execute_reply.started": "2022-07-19T10:30:49.753809Z",
     "shell.execute_reply": "2022-07-19T10:30:49.766425Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Restore the latest checkpoint and test"
   ],
   "metadata": {
    "id": "n250XbnjOaqP",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ],
   "metadata": {
    "id": "UJpT9D5_OgP6",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:30:49.768942Z",
     "iopub.execute_input": "2022-07-19T10:30:49.769315Z",
     "iopub.status.idle": "2022-07-19T10:30:50.280249Z",
     "shell.execute_reply.started": "2022-07-19T10:30:49.769280Z",
     "shell.execute_reply": "2022-07-19T10:30:50.279385Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Final translations with Attention Plots"
   ],
   "metadata": {
    "id": "nSAbQknGT8De",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "translate(\"I picked a card from a deck.\", True)"
   ],
   "metadata": {
    "id": "8gh6GNJRbbGG",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:30:50.282230Z",
     "iopub.execute_input": "2022-07-19T10:30:50.283213Z",
     "iopub.status.idle": "2022-07-19T10:30:50.687633Z",
     "shell.execute_reply.started": "2022-07-19T10:30:50.283175Z",
     "shell.execute_reply": "2022-07-19T10:30:50.686435Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation\n"
   ],
   "metadata": {
    "id": "1Id33nNDcMs_",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def metric(target,output):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    reference = [target.split(\" \")]\n",
    "    candidate = output.split(\" \")\n",
    "    score = sentence_bleu(reference, candidate)\n",
    "    return score\n"
   ],
   "metadata": {
    "id": "YkZchsMbcO18",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:30:50.689059Z",
     "iopub.execute_input": "2022-07-19T10:30:50.689613Z",
     "iopub.status.idle": "2022-07-19T10:30:50.696598Z",
     "shell.execute_reply.started": "2022-07-19T10:30:50.689578Z",
     "shell.execute_reply": "2022-07-19T10:30:50.695241Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    eng, ita, _ = line.split(\"\\t\")\n",
    "    ita = \"[start] \" + ita + \" [end]\"\n",
    "    text_pairs.append((eng, ita))"
   ],
   "metadata": {
    "id": "_J7nfxVUj4tk",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:30:50.697997Z",
     "iopub.execute_input": "2022-07-19T10:30:50.698477Z",
     "iopub.status.idle": "2022-07-19T10:30:51.257886Z",
     "shell.execute_reply.started": "2022-07-19T10:30:50.698441Z",
     "shell.execute_reply": "2022-07-19T10:30:51.256912Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "num_train_samples = int(len(text_pairs)*0.80)\n",
    "train_pairs = text_pairs[:num_train_samples ]\n",
    "test_pairs = text_pairs[num_train_samples:]\n",
    "print(\"\")\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")"
   ],
   "metadata": {
    "id": "O5Ucbxu5j16j",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:30:51.259085Z",
     "iopub.execute_input": "2022-07-19T10:30:51.259450Z",
     "iopub.status.idle": "2022-07-19T10:30:51.272133Z",
     "shell.execute_reply.started": "2022-07-19T10:30:51.259414Z",
     "shell.execute_reply": "2022-07-19T10:30:51.270875Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def clean(word):\n",
    "    clean_word = word.lower()\n",
    "    clean_word = clean_word.replace(\".\",\"\")\n",
    "    clean_word = clean_word.replace(\"\\\"\",\"\")\n",
    "    clean_word = clean_word.replace(\",\",\"\")\n",
    "    clean_word = clean_word.replace(\"[start]\",\"\")\n",
    "    clean_word = clean_word.replace(\"[end]\",\"\")\n",
    "    clean_word = clean_word.strip()\n",
    "    return clean_word"
   ],
   "metadata": {
    "id": "KQBLJdB9lT6e",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:30:51.274016Z",
     "iopub.execute_input": "2022-07-19T10:30:51.274778Z",
     "iopub.status.idle": "2022-07-19T10:30:51.281522Z",
     "shell.execute_reply.started": "2022-07-19T10:30:51.274741Z",
     "shell.execute_reply": "2022-07-19T10:30:51.280675Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_metric_on_testset():\n",
    "    try:\n",
    "        result = 0\n",
    "        count = 0\n",
    "        for i,item in enumerate(test_pairs[0:30]):\n",
    "            input_eng = clean(item[0])   #eng\n",
    "            target = clean(item[1])  #ita\n",
    "            output = clean(translate(input_eng))\n",
    "            item_result = metric(target,output)\n",
    "            #print(input_eng,\"->\",output, \" \",target,item_result)\n",
    "            print(\"=================== TEST #\", i, \"===================\")\n",
    "            print(\"ðŸ‡®ðŸ‡¹ \",target)\n",
    "            print(\"ðŸ‡ºðŸ‡¸ \",input_eng)\n",
    "            print(\"Translated: \",output)\n",
    "            print(\"BLEU score: \", item_result)\n",
    "            result+=item_result\n",
    "            count+=1\n",
    "\n",
    "        final_result = result/count\n",
    "        return final_result\n",
    "    except Exception as e:\n",
    "        print(\">>> Exception:\", e)\n",
    "        return -1"
   ],
   "metadata": {
    "id": "tBxDWBhJcTvA",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:30:51.283199Z",
     "iopub.execute_input": "2022-07-19T10:30:51.283693Z",
     "iopub.status.idle": "2022-07-19T10:30:51.306296Z",
     "shell.execute_reply.started": "2022-07-19T10:30:51.283652Z",
     "shell.execute_reply": "2022-07-19T10:30:51.305139Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\nResult:\", calculate_metric_on_testset())"
   ],
   "metadata": {
    "id": "Cb5jQyx6cU21",
    "execution": {
     "iopub.status.busy": "2022-07-19T10:30:51.307528Z",
     "iopub.execute_input": "2022-07-19T10:30:51.308440Z",
     "iopub.status.idle": "2022-07-19T10:30:53.465134Z",
     "shell.execute_reply.started": "2022-07-19T10:30:51.308405Z",
     "shell.execute_reply": "2022-07-19T10:30:53.464230Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "token = \"5597879510:AAH1FSuZa7lA_xoAp-7JiUDE0OY38p-Tq5M\"\n",
    "theUrl = \"https://api.telegram.org/bot\" + token + \"/sendMessage\"\n",
    "who = \"-606080513\"\n",
    "\n",
    "def sendMessage(text=\"\"):\n",
    "    import json\n",
    "    import requests\n",
    "    data = {'chat_id': who, 'disable_notification': 'false', 'text': text}\n",
    "    headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
    "    requests.post(theUrl, data=json.dumps(data, ensure_ascii=True), headers=headers)\n",
    "\n",
    "def sendFile(file):\n",
    "    import telepot\n",
    "    f = open(file, 'rb')\n",
    "    bot = telepot.Bot(token)\n",
    "    bot.sendDocument(who, f)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-19T10:45:30.902006Z",
     "iopub.execute_input": "2022-07-19T10:45:30.902432Z",
     "iopub.status.idle": "2022-07-19T10:45:30.909972Z",
     "shell.execute_reply.started": "2022-07-19T10:45:30.902391Z",
     "shell.execute_reply": "2022-07-19T10:45:30.908804Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!ls ./training_checkpoints -al"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-19T10:44:45.116204Z",
     "iopub.execute_input": "2022-07-19T10:44:45.116572Z",
     "iopub.status.idle": "2022-07-19T10:44:45.838129Z",
     "shell.execute_reply.started": "2022-07-19T10:44:45.116533Z",
     "shell.execute_reply": "2022-07-19T10:44:45.836776Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pip install telepot"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-19T10:48:53.626895Z",
     "iopub.execute_input": "2022-07-19T10:48:53.627640Z",
     "iopub.status.idle": "2022-07-19T10:49:05.220446Z",
     "shell.execute_reply.started": "2022-07-19T10:48:53.627584Z",
     "shell.execute_reply": "2022-07-19T10:49:05.218637Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!zip -r method1_lstm.zip training_checkpoints\n",
    "\n",
    "!split -b 45m method1_lstm.zip method1_lstm.zip.pt_"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sendMessage(\"Questo serve a Denny, preparatevi.\")"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for file in os.listdir(os.getcwd()):\n",
    "        if file.startswith(\"method1_lstm.zip.pt_\"):\n",
    "            sendFile(file)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-19T10:49:05.222882Z",
     "iopub.execute_input": "2022-07-19T10:49:05.223293Z",
     "iopub.status.idle": "2022-07-19T10:51:14.215495Z",
     "shell.execute_reply.started": "2022-07-19T10:49:05.223252Z",
     "shell.execute_reply": "2022-07-19T10:51:14.214514Z"
    },
    "trusted": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}